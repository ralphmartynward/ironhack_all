{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pymysql\n",
    "#!pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report, f1_score, cohen_kappa_score\n",
    "\n",
    "import getpass  # To get the password without showing the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "password = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string = 'mysql+pymysql://root:'+password+'@localhost/bank'\n",
    "engine = create_engine(connection_string)\n",
    "data = pd.read_sql_query('SELECT * FROM loan', engine)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative: use engine.execute()\n",
    "result = engine.execute('SELECT * FROM loan')\n",
    "\n",
    "print(\"The type of result is: \",type(result))\n",
    "print()\n",
    "\n",
    "rows = []\n",
    "for row in result:\n",
    "    rows.append(row)\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use execute to change things in the database, e.g.,\n",
    "# engine.execute(\"DROP DATABASE IF EXISTS BootCamps\")\n",
    "# engine.execute(\"CREATE DATABASE IF NOT EXISTS BootCamps\")\n",
    "# engine.execute(\"USE BootCamps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# longer queries:\n",
    "query = 'SELECT order_id AS \"OrderID\", account_id AS \"AccountID\", bank_to AS \"DestinationBank\", amount  AS \"Amount\" \\\n",
    "FROM bank.order \\\n",
    "WHERE k_symbol = \"SIPO\" \\\n",
    "LIMIT 100'\n",
    "data = pd.read_sql_query(query, engine)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activity 1\n",
    "\n",
    "# In this activity, we will be using the table district from the bank database and \n",
    "# according to the description for the different columns:\n",
    "\n",
    "# Create the connection between SQL and Python and extract all the information \n",
    "#   from the loan table where the status is either A or B.\n",
    "# Use the executable class to run the query/queries. \n",
    "# You can test the query/queries in Workbench and then use them with Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connection_string = 'mysql+pymysql://root:' + password + '@localhost/bank'\n",
    "# engine = create_engine(connection_string)\n",
    "# option 1\n",
    "data = pd.read_sql_query(\"SELECT * FROM bank.loan where status in ('A', 'B') \", engine)\n",
    "# option 2\n",
    "# result = engine.execute('SELECT * FROM bank.loan where status in (\"A\", \"B\")')\n",
    "\n",
    "# rows = [row for row in result]\n",
    "# data = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# end of Activity 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intro of logistic regression (see slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the data for our logistic regression example\n",
    "\n",
    "# this is another way to write a statement that uses more than one line\n",
    "query = '''select * from trans as t\n",
    "left join loan as l\n",
    "on t.account_id = l.account_id\n",
    "where l.status in ('A', 'B');'''\n",
    "\n",
    "data = pd.read_sql_query(query, engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# better to use explicit names, otherwise we get duplicate column names\n",
    "query = '''select t.type, t.operation, t.amount as t_amount, t.balance, t.k_symbol, l.amount as l_amount, l.duration, l.payments, l.status\n",
    "from trans t\n",
    "left join loan l\n",
    "on t.account_id = l.account_id\n",
    "where l.status in ('A', 'B');'''\n",
    "\n",
    "data = pd.read_sql_query(query, engine)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start of our analysis and modelling\n",
    "#data.shape\n",
    "#data.dtypes\n",
    "data['duration'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['duration'] = data['duration'].astype('object') # This will be treated as categorical\n",
    "data.describe().T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## checking all the categorical columns\n",
    "data['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since we have a lot values for operation which are of type vyber,\n",
    "# we are not removing that data from type column\n",
    "data['operation'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanOperation(x):\n",
    "    x = x.lower()\n",
    "    if 'vyber' in x:\n",
    "        return \"vyber\"\n",
    "    elif 'prevod' in x:\n",
    "        return \"prevod\"\n",
    "    elif 'vklad' in x:\n",
    "        return 'vklad'\n",
    "    else:\n",
    "        return 'unknown'\n",
    "\n",
    "data['operation'] = list(map(cleanOperation, data['operation']))\n",
    "#data['operation'] = data['operation'].apply(lambda x: cleanOperation(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['operation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['k_symbol'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['k_symbol'].value_counts().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleankSymbol(x):\n",
    "    x = x.lower()\n",
    "    if x in ['', ' ']:\n",
    "        return 'unknown'\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "data['k_symbol'] = list(map(cleankSymbol, data['k_symbol']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['k_symbol'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the rows for the smallest k_symbols\n",
    "# with drop: rows_to_drop = data[~data['k_symbol'].isin(['pojistne', 'sankc. urok', 'uver'])].index\n",
    "# data = data.drop(rows_to_drop, axis = 0)\n",
    "# data.drop(rows_to_drop, axis = 0, inplace = True)\n",
    "data = data[~data['k_symbol'].isin(['pojistne', 'sankc. urok', 'uver'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['k_symbol'].value_counts()\n",
    "#data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['duration'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanDuration(x):\n",
    "    if x in [48, 60]:\n",
    "        return 'other'\n",
    "    else:\n",
    "        return str(x)\n",
    "data['duration'] = list(map(cleanDuration, data['duration']))\n",
    "data.head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['duration'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for multicollinearity\n",
    "\n",
    "corr_matrix=data.corr(method='pearson')  # default\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "ax = sns.heatmap(corr_matrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build X and y\n",
    "y = data['status']\n",
    "X = data.drop(['status'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split numericals and categoricals\n",
    "X_train_df = pd.DataFrame(X_train, columns=X.columns)\n",
    "X_test_df  = pd.DataFrame(X_test,  columns=X.columns)\n",
    "\n",
    "X_train_num = X_train_df.select_dtypes(include = np.number)\n",
    "X_test_num  = X_test_df.select_dtypes(include = np.number)\n",
    "X_train_cat = X_train_df.select_dtypes(include = np.object)\n",
    "X_test_cat  = X_test_df.select_dtypes(include = np.object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distributions for numericals\n",
    "sns.displot(X_train_num['t_amount'])\n",
    "plt.show()\n",
    "\n",
    "sns.displot(X_train_num['l_amount'])\n",
    "plt.show()\n",
    "\n",
    "sns.displot(X_train_num['balance'])\n",
    "plt.show()\n",
    "\n",
    "sns.displot(X_train_num['payments'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale numericals\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Normalizing data\n",
    "transformer = MinMaxScaler()\n",
    "transformer.fit(X_train_num) # we will reuse this transformer for X_test later\n",
    "X_train_scaled = transformer.transform(X_train_num)\n",
    "X_test_scaled  = transformer.transform(X_test_num)\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train_num.columns)\n",
    "X_train_scaled.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode categoricals\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(drop='first') # The option drop='first' drops one of the possible values.\n",
    "encoder.fit(X_train_cat)\n",
    "X_train_cat_encoded = encoder.transform(X_train_cat).toarray()\n",
    "cols = encoder.get_feature_names(input_features=X_train_cat.columns)\n",
    "# Note: in version 1.0 and higher of sklearn this method is called 'get_feature_names_out()'\n",
    "# we will reuse encoder and cols when encoding the X_test_cat\n",
    "X_train_encoded_df = pd.DataFrame(X_train_cat_encoded, columns=cols)\n",
    "X_train_encoded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_treated_df = pd.concat([X_train_scaled, X_train_encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classification = LogisticRegression(random_state=0, solver='lbfgs',\n",
    "                  multi_class='ovr')\n",
    "\n",
    "classification.fit(X_train_treated_df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply scaler to X_test_num\n",
    "X_test_scaled = transformer.transform(X_test_num)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test_num.columns)\n",
    "X_test_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply encoded to X_test_cat\n",
    "encoded_test_cat = encoder.transform(X_test_cat).toarray()\n",
    "onehot_encoded_test_df = pd.DataFrame(encoded_test_cat, columns=cols)\n",
    "onehot_encoded_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine scaled and onehot_encoded portions of X_test\n",
    "X_test_treated_df = pd.concat([X_test_scaled, onehot_encoded_test_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = classification.predict(X_train_treated_df)\n",
    "y_test_pred  = classification.predict(X_test_treated_df)\n",
    "print(\"The first predictions on the TRAIN set are: \",y_train_pred[:5])\n",
    "print(\"The first predictions on the TEST set are: \",y_test_pred[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The confusion matrix on the TRAIN set is: \")\n",
    "cm_train = confusion_matrix(y_train, y_train_pred)\n",
    "cm_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#              Predicted Labels\n",
    "#              | A  | B\n",
    "# -----------------------\n",
    "# True label A |    |\n",
    "#            ------------\n",
    "#            B |    |\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = ConfusionMatrixDisplay(cm_train,display_labels=classification.classes_);\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The confusion matrix on the TEST set is: \")\n",
    "cm_test = confusion_matrix(y_test, y_test_pred)\n",
    "cm_test\n",
    "disp = ConfusionMatrixDisplay(cm_test,display_labels=classification.classes_);\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification.score == accuracy of prediction\n",
    "# Accuracy score = (TP + TN)/(TP + TN + FP + FN)\n",
    "print(\"The accuracy in the TRAIN set is: {:.3f}\".format(accuracy_score(y_train, y_train_pred)))\n",
    "print(\"The accuracy in the TEST  set is: {:.3f}\".format(accuracy_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The accuracy in the TRAIN set is: {:.3f}\".format((48335+959)/(48335+959+6309+400)))\n",
    "print(\"The accuracy in the TEST  set is: {:.3f}\".format((12112+234)/(12112+234+1565+90)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precission score. = TP/(TP + FP)\n",
    "#If we're using labels instead of numbers for the classes to predict, we need to\n",
    "# provide what class is the \"positive\" and which is the \"negative\"\n",
    "print(\"The precission in the TRAIN set is: {:.3f}\".format(precision_score(y_train, y_train_pred, pos_label=\"A\")))\n",
    "print(\"The precission in the TEST  set is: {:.3f}\".format(precision_score(y_test, y_test_pred, pos_label=\"A\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The precission in the TRAIN set is: {:.3f}\".format(48335/(48335+6309)))\n",
    "print(\"The precission in the TEST  set is: {:.3f}\".format(12112/(12112+1564)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall score = TP / ( TP + FN)\n",
    "print(\"The recall in the TRAIN set is: {:.3f}\".format(recall_score(y_train, y_train_pred, pos_label=\"A\")))\n",
    "print(\"The recall in the TEST  set is: {:.3f}\".format(recall_score(y_test,  y_test_pred, pos_label=\"A\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The recall in the TRAIN set is: {:.3f}\".format(48335/(48335+400)))\n",
    "print(\"The recall in the TEST  set is: {:.3f}\".format(12112/(12112+90)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The F1-score for the TRAIN set is {:.2f}\".format(f1_score(y_train,y_train_pred, pos_label=\"A\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The F1-score for the TEST set is {:.2f}\".format(f1_score(y_test,y_test_pred, pos_label=\"A\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_train_pred,target_names=['A','B']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_test_pred,target_names=['A','B']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_np = np.array(y_test)\n",
    "len(list(y_test_np[y_test_np == 'A']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "12202 + 1799"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
